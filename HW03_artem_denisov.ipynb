{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14ad4ef7",
   "metadata": {},
   "source": [
    "Домашняя работа №3 по курсу \"Продвинутое машинное обучение\"\n",
    "выполнил Денисов Артем MADE-ML-22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "ac049384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pprint import pprint\n",
    "from typing import List, Dict\n",
    "from random import shuffle, seed, choices, random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8483954",
   "metadata": {},
   "source": [
    "1. Реализуйте базовый частотный метод по Шерлоку Холмсу\n",
    "○\tподсчитайте частоты букв по корпусам (пунктуацию и капитализацию можно просто опустить, а вот пробелы лучше оставить);\n",
    "○\tвозьмите какие-нибудь тестовые тексты (нужно взять по меньшей мере 2-3 предложения, иначе вряд ли сработает), зашифруйте их посредством случайной перестановки символов;\n",
    "○\tрасшифруйте их таким частотным методом.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "131a179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHABET = 'абвгдежзийклмнопрстуфхцчшщъыьэюя' + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f28e2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_text_file(filepath):\n",
    "    text = []\n",
    "    with open(filepath, encoding='utf-8') as file:\n",
    "        for row in file:\n",
    "            text.append(row)\n",
    "    return ''.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "aa586987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, alphabet):\n",
    "    new_text = []\n",
    "    for letter in text.lower():\n",
    "        if letter in alphabet:\n",
    "            new_text.append(letter)\n",
    "    return ''.join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "8cfc2590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_letter_frequency(text, alphabet):\n",
    "    frequency_dict = {letter: 0 for letter in alphabet}\n",
    "    for letter in text:\n",
    "        frequency_dict[letter] += 1\n",
    "    return frequency_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "7ebf80b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(717873, 649364)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = open_text_file('WarAndPeace.txt')\n",
    "processed_corpus = preprocess_text(corpus, ALPHABET)\n",
    "train_frequency = build_letter_frequency(processed_corpus, ALPHABET)\n",
    "len(corpus), len(processed_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20ad6907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_text(text, alphabet):\n",
    "    seed(42)\n",
    "    shuffled_text = []\n",
    "    \n",
    "    shuffled_alphabet_list = [letter for letter in alphabet]\n",
    "    alphabet_list = [letter for letter in alphabet]\n",
    "    shuffle(shuffled_alphabet_list)\n",
    "    shuffle_mapping = {a: b for a, b in zip(alphabet_list, shuffled_alphabet_list)} \n",
    "    for letter in text:\n",
    "        if letter in alphabet:\n",
    "            shuffled_text.append(shuffle_mapping[letter])\n",
    "        else:\n",
    "            shuffled_text.append(letter)\n",
    "    return ''.join(shuffled_text), shuffle_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "cf1282b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'мне теперь так ясна моя мысль  говорил толстой в  году завершая работу над романом  так в анне карениной я люблю мысль семейную в войне и мире любил мысль народную вследствие войны  года конечно и в войне и мире есть семейная хроника и в анне карениной есть картины народной жизни но для каждого романа нужна была своя особенная любовь мысль семейная для х годов  века особенно актуальна одна из самых важных задач в этом текущем для меня например  признавался фм достоевский  молодое поколение и вместе с тем современная русская семья которая я предчувствую это далеко не такова как всего еще двадцать лет назад'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = \"«Мне теперь так ясна моя мысль, – говорил Толстой в 1877 году, завершая работу над романом. – Так, в „Анне Карениной“ я люблю мысль семейную, в „Войне и мире“ любил мысль народную вследствие войны 1812 года…».[25] Конечно, и в «Войне и мире» есть «семейная хроника», и в «Анне Карениной» есть «картины народной жизни». Но для каждого романа нужна была своя, особенная любовь. «Мысль семейная» для 70-х годов XIX века особенно актуальна. «Одна из самых важных задач в этом текущем, для меня, например, – признавался Ф.М. Достоевский, – молодое поколение, и вместе с тем современная русская семья, которая, я предчувствую это, далеко не такова, как всего еще двадцать лет назад».[26]\"\n",
    "test_text = preprocess_text(test_text, ALPHABET)\n",
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "de7bb982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'йэмзямжмщ зяыузбаэызйшбзйьац ззршлшщкцзяшцаяшозлззршънзпылмщгыбзщыешянзэыъзщшйыэшйззяыузлзыээмзуыщмэкэшозбзцчецчзйьац замймоэнчзлзлшоэмзкзйкщмзцчекцзйьац зэыщшъэнчзлацмъаялкмзлшоэьззршъызушэмхэшзкзлзлшоэмзкзйкщмзмая замймоэыбзвщшэкуызкзлзыээмзуыщмэкэшозмая зуыщякэьзэыщшъэшозфкпэкзэшзъцбзуыфъшршзщшйыэызэнфэызеьцызалшбзшашемээыбзцчешл зйьац замймоэыбзъцбзвзршъшлззлмуызшашемээшзыуяныц эызшъэызкпзаыйьвзлыфэьвзпыъыхзлзияшйзямунюмйзъцбзймэбзэыжщкймщззжщкпэылыцабзтйзъшаяшмлаукоззйшцшъшмзжшушцмэкмзкзлймаямзазямйзашлщмймээыбзщнаауыбзамй бзушяшщыбзбзжщмъхнлаялнчзияшзъыцмушзэмзяыушлызуыузламршзмюмзълыъсыя зцмязэыпыъ'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_text, shuffle_mapping = shuffle_text(test_text, ALPHABET)\n",
    "shuffled_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c088b838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_decoding_mapping(train_frequency, test_frequency):\n",
    "    train_frequency_list = [(value, key) for key, value in train_frequency.items()]\n",
    "    train_frequency_list.sort(reverse=True)\n",
    "    test_frequency_list = [(value, key) for key, value in test_frequency.items()]\n",
    "    test_frequency_list.sort(reverse=True)\n",
    "    decoding_mapping = dict()\n",
    "    for i in range(len(test_frequency_list)):\n",
    "        train_counter, train_letter = train_frequency_list[i]\n",
    "        test_counter, test_letter = test_frequency_list[i]\n",
    "        decoding_mapping[test_letter] = train_letter\n",
    "    return decoding_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "298394a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_text(text, mapping):\n",
    "    decoded_text = []\n",
    "    for letter in text:\n",
    "        decoded_text.append(mapping[letter])\n",
    "    return ''.join(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "b2ff1add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'з': ' ', 'ш': 'о', 'ы': 'а', 'м': 'е', 'э': 'и', 'а': 'н', 'л': 'т', 'й': 'с', 'я': 'л', 'ц': 'в', 'щ': 'р', 'к': 'к', 'ъ': 'д', 'у': 'м', 'б': 'у', 'о': 'п', ' ': 'я', 'н': 'г', 'ь': 'ь', 'ч': 'ы', 'е': 'з', 'р': 'б', 'п': 'ч', 'ж': 'й', 'ф': 'ж', 'в': 'ш', 'х': 'х', 'ю': 'ю', 'и': 'ц', 'т': 'э', 'с': 'щ', 'г': 'ф', 'д': 'ъ'}\n"
     ]
    }
   ],
   "source": [
    "test_frequency = build_letter_frequency(shuffled_text, ALPHABET)\n",
    "decode_mapping = make_decoding_mapping(train_frequency, test_frequency)\n",
    "print(decode_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "a612e809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "сие лейеря лам униа соу сьнвя  боторкв ловнлоп т  бодг чатерфау разолг иад росаиос  лам т аиие мареикиоп у вызвы сьнвя несепигы т топие к скре вызкв сьнвя иародигы тнведнлтке топиь  бода моиехио к т топие к скре енля несепиау шроикма к т аиие мареикиоп енля марлкиь иародиоп жкчик ио дву маждобо росаиа игжиа зьва нтоу онозеииау вызотя сьнвя несепиау дву ш бодот  тема онозеиио амлгавяиа одиа кч насьш тажиьш чадах т цлос лемгюес дву сеиу иайрксер  йркчиатавну эс донлоетнмкп  соводое йомовеике к тсенле н лес нотресеииау ргннмау несяу молорау у йредхгтнлтгы цло давемо ие ламота мам тнебо еюе дтадщаля вел иачад\n"
     ]
    }
   ],
   "source": [
    "decoded_text = decode_text(shuffled_text, decode_mapping)\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "4cf18336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'мне теперь так ясна моя мысль  говорил толстой в  году завершая работу над романом  так в анне карениной я люблю мысль семейную в войне и мире любил мысль народную вследствие войны  года конечно и в войне и мире есть семейная хроника и в анне карениной есть картины народной жизни но для каждого романа нужна была своя особенная любовь мысль семейная для х годов  века особенно актуальна одна из самых важных задач в этом текущем для меня например  признавался фм достоевский  молодое поколение и вместе с тем современная русская семья которая я предчувствую это далеко не такова как всего еще двадцать лет назад'"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "75c04a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def letter_accuracy(true_text, decoded_text, alphabet):\n",
    "    all_answers = 0\n",
    "    correct_answers = 0\n",
    "    for letter_true, letter_decoded in zip(true_text, decoded_text):\n",
    "        if letter_decoded in alphabet:\n",
    "            if letter_true == letter_decoded:\n",
    "                correct_answers += 1\n",
    "            all_answers += 1\n",
    "    return correct_answers / all_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "4fb22c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.487\n"
     ]
    }
   ],
   "source": [
    "print(f\"{letter_accuracy(test_text, decoded_text, ALPHABET):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "97f901b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_test = \"დჳჵჂႨშႼႨშჂხჂჲდႨსႹႭჾႣჵისႼჰႨჂჵჂႨႲႹႧჲჂႨსႹႭჾႣჵისႼჰႨჲდႩჳჲႨჇႨႠჲႹქႹႨჳႹႹჱჶდსჂႽႨႩႹჲႹႭႼჰႨჵდქႩႹႨႲႭႹႧჂჲႣჲიႨჳႩႹႭდდႨშჳდქႹႨშႼႨშჳდႨჳხდჵႣჵჂႨႲႭႣშჂჵისႹႨჂႨႲႹჵჇႧჂჲდႨჾႣႩჳჂჾႣჵისႼჰႨჱႣჵჵႨეႣႨႲႹჳჵდხსდდႨႧდჲშდႭჲႹდႨეႣხႣსჂდႨႩჇႭჳႣႨႾႹჲႽႨႩႹსდႧსႹႨႽႨსჂႧდქႹႨსდႨႹჱდჶႣნ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "466e2a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_letter_frequency_bigram(text, n=2):\n",
    "    frequency_dict = dict()\n",
    "    for letter_index in range(len(text) - n + 1):\n",
    "        bigram = text[letter_index:letter_index + n]\n",
    "        if bigram in frequency_dict.keys():\n",
    "            frequency_dict[bigram] += 1\n",
    "        else:\n",
    "            frequency_dict[bigram] = 1\n",
    "    return frequency_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "926e166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_text_bigram(text, mapping, n=2):\n",
    "    decoded_text = []\n",
    "    for letter_index in range(len(text) - n + 1):\n",
    "        bigram = text[letter_index:letter_index + n]\n",
    "        decoded_text.append(mapping[bigram][0])\n",
    "    decoded_text.append(mapping[bigram][1])\n",
    "    return ''.join(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "fd588c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 199)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_frequency_bigram = build_letter_frequency_bigram(text)\n",
    "test_frequency_bigram = build_letter_frequency_bigram(shuffled_text)\n",
    "len(train_frequency_bigram), len(test_frequency_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "a511a27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_mapping = make_decoding_mapping(train_frequency_bigram, test_frequency_bigram)\n",
    "decoded_text_bigram = decode_text_bigram(shuffled_text, decode_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "e57866cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'шъдж–щчшящждшщгххэъщтщ,щйыжхщщжхцлщыфщжщъшщщщфщйщжхщ цйщюхшяцъ,йю[йь»цюэщ„йчщущэщйщждшщщйсщэъдщлшчхэхэщфг,жхъцххщйыжхщэ.пйцзэщхщйщлщзъдюгщтхчджхъцфщщйыжхщюэшчщьэщхщтжфц„щ»щфдщлщзяющжхщыъщхъъъюэшюгщйщлщзъдюгщтхчдйцщгщэ.пйцзэъ,йхчъэшлъюгщйсщэъдщлшчхэхэщфйцщгщщлшяйхяююэшчщьэщфчыфцэгюэшвыъ,щлюыщяхшйчщущэъюэъчэъчцзюъэхлщ,оъбщйхээъ,жхъйцшщщйыжхщэ.пйцзэъ,выъ,йбжхщщцйщщхчлъоъбщйхээшсшы»ъэххэъощьэъюфъэхайюбщфючяюбйщщыгьщййлщщйж–чыъ“пйвыъ,щйхи,юэ«гышйшящйгыфцэюфэшх,чыйвщъщщщщтйышфщщтъющщщдйчяхъфхэфдюгщщйцщ–дэхж–пйэбцщчпйхээъ,йяъхйлъ,э.пшх,щхьщщюъ,г,йгчц1эътщ»щщхйлщшвыэфчхшюъдждшхцфъщлшщщт.щхшйъ“дв…фщ.ыжгщжфъиюэгщщч'"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_text_bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "d7d0b2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010\n"
     ]
    }
   ],
   "source": [
    "alphabet = ''.join(set(decoded_text_bigram))\n",
    "print(f\"{letter_accuracy(test_text, decoded_text_bigram, alphabet):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4a2163",
   "metadata": {},
   "source": [
    "Биграммы - это марковская цепь\n",
    "из корпуса получаю вероятность перехода из буквы в букву"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "cd5f8ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_probabilites(corpus, alphabet, n_gram=2):\n",
    "    n_text = len(corpus)\n",
    "    prob_dict = {letter: dict() for letter in alphabet}\n",
    "    for i in range(n_text - n_gram):\n",
    "        letter = corpus[i]\n",
    "        next_letter = corpus[i + 1]\n",
    "        if letter in alphabet and next_letter in alphabet:\n",
    "            if next_letter in prob_dict[letter].keys():\n",
    "                prob_dict[letter][next_letter] += 1\n",
    "            else:\n",
    "                prob_dict[letter][next_letter] = 1\n",
    "                \n",
    "    for letter in alphabet:\n",
    "        letter_sum_probability = sum(prob_dict[letter].values())\n",
    "        for next_letter in prob_dict[letter].keys():\n",
    "            prob_dict[letter][next_letter] /= letter_sum_probability\n",
    "            \n",
    "    for letter in alphabet:\n",
    "        letter_sum_probability = sum(prob_dict[letter].values())\n",
    "        for next_letter in prob_dict[letter].keys():\n",
    "            prob_dict[letter][next_letter] /= n_text\n",
    "            \n",
    "    return prob_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "84f3fe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_probability(text, prob_dict, ngram=2):\n",
    "    n_text = len(text)\n",
    "    log_prob = 0\n",
    "    for i in range(n_text - n_gram):\n",
    "        n_letters = text[i:i + ngram]\n",
    "        if n_letters in prob_dict.keys():\n",
    "            log_prob += np.log(prob_dict[n_letters])\n",
    "        else:\n",
    "            log_prob += -10000\n",
    "    return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "fcb1ea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_dict = estimate_probabilites(processed_corpus, ALPHABET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "0a4366dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_text_mcmm(text, prob_dict, alphabet, n_steps=1000):\n",
    "    decoded_text = ''\n",
    "    current_log_proba = count_probability(text, prob_dict)\n",
    "    mapping_for_decoding = {letter: letter for letter in alphabet}\n",
    "    accepted_steps = 0\n",
    "    for i in range(n_steps):\n",
    "        letter_one, letter_two = choices(alphabet, k=2)\n",
    "        test_mapping = mapping_for_decoding.copy()\n",
    "        test_mapping[letter_one], test_mapping[letter_two] = test_mapping[letter_two], test_mapping[letter_one]\n",
    "        try_decoded_text = decode_text(text, test_mapping)\n",
    "        new_prob = count_probability(try_decoded_text, prob_dict)\n",
    "        \n",
    "        prob_condition = np.exp(new_prob - current_log_proba)\n",
    "        if prob_condition > random():\n",
    "            accepted_steps += 1\n",
    "            mapping_for_decoding = test_mapping\n",
    "            current_log_proba = new_prob\n",
    "    return mapping_for_decoding, current_log_proba, accepted_steps / n_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "f8687a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-258-e43fa0bdfdcf>:13: RuntimeWarning: overflow encountered in exp\n",
      "  prob_condition = np.exp(new_prob - current_log_proba)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -10091.692553649238 0.037533333333333335\n",
      "нр ет г дьетомешсроенашенусвьеещаладиветавстафелеещазбепол дцошедохатберозеданоранеетомелеорр емод рирафешевыхвыенусвьес н фрбыелелафр еиенид евыхивенусвьеродазрбыелсв зстли елафруеещазоемар яраеиелелафр еиенид е стьес н фрошеждаримоеиелеорр емод рирафе стьемодтируеродазрафекиприераезвшемокзащаеданороербкроехувоеслашеасах ррошевыхальенусвьес н фрошезвшежещазалеел моеасах рраеомтбовьроеазроеипесонужелокружепозояелечтанет мбэ незвшен ршерогдин деегдипроловсшейнезаста лсмифеенаваза егамав ри еиелн ст есет несалд н ррошедбссмошес ньшематадошешегд зяблстлбыечтаезов маер етомалоемомелс щае э езлозюотьев теропоз\n",
      "0.134\n",
      "1 -9716.86373979716 0.0396\n",
      "мне теперь так ясна моя мысль  говорил толстой в  году завершая работу над романом  так в анне карениной я люблю мысль семейную в войне и мире любил мысль народную вследствие войны  года конехно и в войне и мире есть семейная чроника и в анне карениной есть картины народной жизни но для каждого романа нужна была своя особенная любовь мысль семейная для ч годов  века особенно актуальна одна из самыч важныч задах в этом текущем для меня например  признавался фм достоевский  молодое поколение и вместе с тем современная русская семья которая я предхувствую это далеко не такова как всего еще двадцать лет назад\n",
      "0.989\n",
      "2 -9978.163072917185 0.038533333333333336\n",
      "3 -10306.105553178955 0.037866666666666667\n",
      "4 -10018.614167333626 0.039733333333333336\n",
      "5 -10219.895854312543 0.038533333333333336\n",
      "6 -9784.871800318155 0.04173333333333333\n",
      "7 -9918.76925121137 0.037866666666666667\n",
      "8 -10210.451202954622 0.0406\n",
      "9 -20546.546755692325 0.037533333333333335\n"
     ]
    }
   ],
   "source": [
    "best_proba = -20000\n",
    "for i in range(20):\n",
    "    mapping, proba, accepted = decode_text_mcmm(shuffled_text, prob_dict, ALPHABET, n_steps=15000)\n",
    "    print(i, proba, accepted)\n",
    "    if proba > best_proba:\n",
    "        best_proba = proba\n",
    "        best_mapping = mapping\n",
    "        decoded_text = decode_text(shuffled_text, best_mapping)    \n",
    "        print(decoded_text)\n",
    "        accuracy = letter_accuracy(test_text, decoded_text, ALPHABET)\n",
    "        print(f\"{accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e95a500",
   "metadata": {},
   "source": [
    "Триграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61640da0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
